{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports:"
      ],
      "metadata": {
        "id": "eO2SggbA04SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras.models import load_model\n",
        "from keras.layers import Embedding, LSTM,GRU\n",
        "\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v3VK2zz_rPU",
        "outputId": "8d1076c4-2ba3-43c0-a9fb-895d1a8a282b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data:"
      ],
      "metadata": {
        "id": "ZhpCmF-Q0_ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "gpi-oQgUB4Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=[]\n",
        "tags = []\n",
        "documents = []\n",
        "puncc = ['?', '!']\n",
        "df = open('intents.json').read()\n",
        "intents = json.loads(df)"
      ],
      "metadata": {
        "id": "iSDYEsuc_rLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI77JP5D6Voi",
        "outputId": "e503eb8c-64af-4dc4-e92f-53a3d36c1c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['Hi',\n",
              "    'How are you?',\n",
              "    'Is anyone there?',\n",
              "    'Hello',\n",
              "    'Good day',\n",
              "    \"What's up\",\n",
              "    'how are ya',\n",
              "    'heyy',\n",
              "    'whatsup',\n",
              "    '??? ??? ??'],\n",
              "   'responses': ['Hello!',\n",
              "    'Good to see you again!',\n",
              "    'Hi there, how can I help?'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['cya',\n",
              "    'see you',\n",
              "    'bye bye',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'I am Leaving',\n",
              "    'Bye',\n",
              "    'Have a Good day',\n",
              "    'talk to you later',\n",
              "    'ttyl',\n",
              "    'i got to go',\n",
              "    'gtg'],\n",
              "   'responses': ['Sad to see you go :(',\n",
              "    'Talk to you later',\n",
              "    'Goodbye!',\n",
              "    'Come back soon'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'creator',\n",
              "   'patterns': ['what is the name of your developers',\n",
              "    'what is the name of your creators',\n",
              "    'what is the name of the developers',\n",
              "    'what is the name of the creators',\n",
              "    'who created you',\n",
              "    'your developers',\n",
              "    'your creators',\n",
              "    'who are your developers',\n",
              "    'developers',\n",
              "    'you are made by',\n",
              "    'you are made by whom',\n",
              "    'who created you',\n",
              "    'who create you',\n",
              "    'creators',\n",
              "    'who made you',\n",
              "    'who designed you'],\n",
              "   'responses': ['College students'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'name',\n",
              "   'patterns': ['name',\n",
              "    'your name',\n",
              "    'do you have a name',\n",
              "    'what are you called',\n",
              "    'what is your name',\n",
              "    'what should I call you',\n",
              "    'whats your name?',\n",
              "    'what are you',\n",
              "    'who are you',\n",
              "    'who is this',\n",
              "    'what am i chatting to',\n",
              "    'who am i taking to',\n",
              "    'what are you'],\n",
              "   'responses': ['You can call me Mind Reader.',\n",
              "    \"I'm Mind Reader\",\n",
              "    'I am a Chatbot.',\n",
              "    'I am your helper'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'hours',\n",
              "   'patterns': ['timing of college',\n",
              "    'what is college timing',\n",
              "    'working days',\n",
              "    'when are you guys open',\n",
              "    'what are your hours',\n",
              "    'hours of operation',\n",
              "    'when is the college open',\n",
              "    'college timing',\n",
              "    'what about college timing',\n",
              "    'is college open on saturday',\n",
              "    'tell something about college timing',\n",
              "    'what is the college  hours',\n",
              "    'when should i come to college',\n",
              "    'when should i attend college',\n",
              "    'what is my college time',\n",
              "    'college timing',\n",
              "    'timing college'],\n",
              "   'responses': ['College is open 8am-5pm Monday-Saturday!'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'number',\n",
              "   'patterns': ['more info',\n",
              "    'contact info',\n",
              "    'how to contact college',\n",
              "    'college telephone number',\n",
              "    'college number',\n",
              "    'What is your contact no',\n",
              "    'Contact number?',\n",
              "    'how to call you',\n",
              "    'College phone no?',\n",
              "    'how can i contact you',\n",
              "    'Can i get your phone number',\n",
              "    'how can i call you',\n",
              "    'phone number',\n",
              "    'phone no',\n",
              "    'call'],\n",
              "   'responses': ['You can contact at: NUMBER'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'course',\n",
              "   'patterns': ['list of courses',\n",
              "    'list of courses offered',\n",
              "    'list of courses offered in',\n",
              "    'what are the courses offered in your college?',\n",
              "    'courses?',\n",
              "    'courses offered',\n",
              "    'courses offered in (your univrsity(UNI) name)',\n",
              "    'courses you offer',\n",
              "    'branches?',\n",
              "    'courses available at UNI?',\n",
              "    'branches available at your college?',\n",
              "    'what are the courses in UNI?',\n",
              "    'what are branches in UNI?',\n",
              "    'what are courses in UNI?',\n",
              "    'branches available in UNI?',\n",
              "    'can you tell me the courses available in UNI?',\n",
              "    'can you tell me the branches available in UNI?',\n",
              "    'computer engineering?',\n",
              "    'computer',\n",
              "    'Computer engineering?',\n",
              "    'it',\n",
              "    'IT',\n",
              "    'Information Technology',\n",
              "    'AI/Ml',\n",
              "    'Mechanical engineering',\n",
              "    'Chemical engineering',\n",
              "    'Civil engineering'],\n",
              "   'responses': ['Our university offers Information Technology, computer Engineering, Mechanical engineering,Chemical engineering, Civil engineering and extc Engineering.'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'fees',\n",
              "   'patterns': ['information about fee',\n",
              "    'information on fee',\n",
              "    'tell me the fee',\n",
              "    'college fee',\n",
              "    'fee per semester',\n",
              "    'what is the fee of each semester',\n",
              "    'what is the fees of each year',\n",
              "    'what is fee',\n",
              "    'what is the fees',\n",
              "    'how much is the fees',\n",
              "    'fees for first year',\n",
              "    'fees',\n",
              "    'about the fees',\n",
              "    'tell me something about the fees',\n",
              "    'What is the fees of hostel',\n",
              "    'how much is the fees',\n",
              "    'hostel fees',\n",
              "    'fees for AC room',\n",
              "    'fees for non-AC room',\n",
              "    'fees for Ac room for girls',\n",
              "    'fees for non-Ac room for girls',\n",
              "    'fees for Ac room for boys',\n",
              "    'fees for non-Ac room for boys'],\n",
              "   'responses': ['For Fee detail visit <a target=\"_blank\" href=\"LINK\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'location',\n",
              "   'patterns': ['where is the college located',\n",
              "    'college is located at',\n",
              "    'where is college',\n",
              "    'where is college located',\n",
              "    'address of college',\n",
              "    'how to reach college',\n",
              "    'college location',\n",
              "    'college address',\n",
              "    'wheres the college',\n",
              "    'how can I reach college',\n",
              "    'whats is the college address',\n",
              "    'what is the address of college',\n",
              "    'address',\n",
              "    'location'],\n",
              "   'responses': ['<a target=\"_blank\" href=\"ADD YOU GOOGLE MAP LINK HERE\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'hostel',\n",
              "   'patterns': ['hostel facility',\n",
              "    'hostel servive',\n",
              "    'hostel location',\n",
              "    'hostel address',\n",
              "    'hostel facilities',\n",
              "    'hostel fees',\n",
              "    'Does college provide hostel',\n",
              "    'Is there any hostel',\n",
              "    'Where is hostel',\n",
              "    'do you have hostel',\n",
              "    'do you guys have hostel',\n",
              "    'hostel',\n",
              "    'hostel capacity',\n",
              "    'what is the hostel fee',\n",
              "    'how to get in hostel',\n",
              "    'what is the hostel address',\n",
              "    'how far is hostel from college',\n",
              "    'hostel college distance',\n",
              "    'where is the hostel',\n",
              "    'how big is the hostel',\n",
              "    'distance between college and hostel',\n",
              "    'distance between hostel and college'],\n",
              "   'responses': ['For hostel detail visit <a target=\"_blank\" href=\"ADD YOUR HOSTEL DETAIL PDF LINK OR ANY INFORMATION LINK OR ADD YOU OWN ANSWERS\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'event',\n",
              "   'patterns': ['events organised',\n",
              "    'list of events',\n",
              "    'list of events organised in college',\n",
              "    'list of events conducted in college',\n",
              "    'What events are conducted in college',\n",
              "    'Are there any event held at college',\n",
              "    'Events?',\n",
              "    'functions',\n",
              "    'what are the events',\n",
              "    'tell me about events',\n",
              "    'what about events'],\n",
              "   'responses': ['For event detail visit <a target=\"_blank\" href=\"ADD YOUR FUNCTIONS LINK OR YOUR OWN RESPONSE\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'document',\n",
              "   'patterns': ['document to bring',\n",
              "    'documents needed for admision',\n",
              "    'documents needed at the time of admission',\n",
              "    'documents needed during admission',\n",
              "    'documents required for admision',\n",
              "    'documents required at the time of admission',\n",
              "    'documents required during admission',\n",
              "    'What document are required for admission',\n",
              "    'Which document to bring for admission',\n",
              "    'documents',\n",
              "    'what documents do i need',\n",
              "    'what documents do I need for admission',\n",
              "    'documents needed'],\n",
              "   'responses': ['To know more about document required visit <a target=\"_blank\" href=\"ADD LINK OF ADMISSION GUIDANCE DOCUMENT FROM YOUR UNIVERSITY WEBSITE\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'floors',\n",
              "   'patterns': ['size of campus',\n",
              "    'building size',\n",
              "    'How many floors does college have',\n",
              "    'floors in college',\n",
              "    'floors in college',\n",
              "    \"how tall is UNI's College of Engineering college building\",\n",
              "    'floors'],\n",
              "   'responses': ['My College has total 2 floors '],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'syllabus',\n",
              "   'patterns': ['Syllabus for IT',\n",
              "    'what is the Information Technology syllabus',\n",
              "    'syllabus',\n",
              "    'timetable',\n",
              "    'what is IT syllabus',\n",
              "    'syllabus',\n",
              "    'What is next lecture'],\n",
              "   'responses': ['Timetable provide direct to the students OR To know about syllabus visit <a target=\"_blank\" href=\"TIMETABLE LINK\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'library',\n",
              "   'patterns': ['is there any library',\n",
              "    'library facility',\n",
              "    'library facilities',\n",
              "    'do you have library',\n",
              "    'does the college have library facility',\n",
              "    'college library',\n",
              "    'where can i get books',\n",
              "    'book facility',\n",
              "    'Where is library',\n",
              "    'Library',\n",
              "    'Library information',\n",
              "    'Library books information',\n",
              "    'Tell me about library',\n",
              "    'how many libraries'],\n",
              "   'responses': ['There is one huge and spacious library.timings are 8am to 6pm and for more visit <a target=\"blank\" href=\"ADD LIBRARY DETAIL LINK\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'infrastructure',\n",
              "   'patterns': ['how is college infrastructure',\n",
              "    'infrastructure',\n",
              "    'college infrastructure'],\n",
              "   'responses': ['Our University has Excellent Infrastructure. Campus is clean. Good IT Labs With Good Speed of Internet connection'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'canteen',\n",
              "   'patterns': ['food facilities',\n",
              "    'canteen facilities',\n",
              "    'canteen facility',\n",
              "    'is there any canteen',\n",
              "    'Is there a cafetaria in college',\n",
              "    'Does college have canteen',\n",
              "    'Where is canteen',\n",
              "    'where is cafetaria',\n",
              "    'canteen',\n",
              "    'Food',\n",
              "    'Cafetaria'],\n",
              "   'responses': ['Our university has canteen with variety of food available'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'menu',\n",
              "   'patterns': ['food menu',\n",
              "    'food in canteen',\n",
              "    'Whats there on menu',\n",
              "    'what is available in college canteen',\n",
              "    'what foods can we get in college canteen',\n",
              "    'food variety',\n",
              "    'What is there to eat?'],\n",
              "   'responses': ['we serve Franky, Locho, Alu-puri, Kachori, Khavsa, Thaali and many more on menu'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'placement',\n",
              "   'patterns': ['What is college placement',\n",
              "    'Which companies visit in college',\n",
              "    'What is average package',\n",
              "    'companies visit',\n",
              "    'package',\n",
              "    'About placement',\n",
              "    'placement',\n",
              "    'recruitment',\n",
              "    'companies'],\n",
              "   'responses': ['To know about placement visit <a target=\"_blank\" href=\"PLACEMENT INFORMATION LINK FROM YOUR UNIVERSITY WEBSITE IF THEY HAVE\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'ithod',\n",
              "   'patterns': ['Who is HOD', 'Where is HOD', 'it hod', 'name of it hod'],\n",
              "   'responses': ['All engineering departments have only one hod XYZ who available on (Place name)'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'computerhod',\n",
              "   'patterns': ['Who is computer HOD',\n",
              "    'Where is computer HOD',\n",
              "    'computer hod',\n",
              "    'name of computer hod'],\n",
              "   'responses': ['All engineering departments have only one hod XYZ who available on (PLACE NAME)'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'extchod',\n",
              "   'patterns': ['Who is extc HOD',\n",
              "    'Where is  extc HOD',\n",
              "    'extc hod',\n",
              "    'name of extc hod'],\n",
              "   'responses': ['Different school wise hod are different.So be more clear with your school or department'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'principal',\n",
              "   'patterns': ['what is the name of principal',\n",
              "    'whatv is the principal name',\n",
              "    'principal name',\n",
              "    'Who is college principal',\n",
              "    \"Where is principal's office\",\n",
              "    'principal',\n",
              "    'name of principal'],\n",
              "   'responses': ['XYZ is college principal and if you need any help then call your branch hod first.That is more appropriate'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'sem',\n",
              "   'patterns': ['exam dates',\n",
              "    'exam schedule',\n",
              "    'When is semester exam',\n",
              "    'Semester exam timetable',\n",
              "    'sem',\n",
              "    'semester',\n",
              "    'exam',\n",
              "    'when is exam',\n",
              "    'exam timetable',\n",
              "    'exam dates',\n",
              "    'when is semester'],\n",
              "   'responses': ['Here is the Academic Calendar  <a target=\"_blank\" href=\"YOUR ACADEMIC CALENDER\">website</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'admission',\n",
              "   'patterns': ['what is the process of admission',\n",
              "    'what is the admission process',\n",
              "    'How to take admission in your college',\n",
              "    'What is the process for admission',\n",
              "    'admission',\n",
              "    'admission process'],\n",
              "   'responses': ['Application can also be submitted online through the Unversity\\'s  <a target=\"_blank\" href=\"LINK OF ADMISSION DOCUMENT\">website</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'scholarship',\n",
              "   'patterns': ['scholarship',\n",
              "    'Is scholarship available',\n",
              "    'scholarship engineering',\n",
              "    'scholarship it',\n",
              "    'scholarship ce',\n",
              "    'scholarship mechanical',\n",
              "    'scholarship civil',\n",
              "    'scholarship chemical',\n",
              "    'scholarship for AI/ML',\n",
              "    'available scholarships',\n",
              "    'scholarship for computer engineering',\n",
              "    'scholarship for IT engineering',\n",
              "    'scholarship for mechanical engineering',\n",
              "    'scholarship for civil engineering',\n",
              "    'scholarship for chemical engineering',\n",
              "    'list of scholarship',\n",
              "    'comps scholarship',\n",
              "    'IT scholarship',\n",
              "    'mechanical scholarship',\n",
              "    'civil scholarship',\n",
              "    'chemical scholarship',\n",
              "    'automobile scholarship',\n",
              "    'first year scholarship',\n",
              "    'second year scholarship',\n",
              "    'third year scholarship',\n",
              "    'fourth year scholarship'],\n",
              "   'responses': ['Many government scholarships are supported by our university. For details and updates visit <a target=\"_blank\" href=\"(SCHOLARSHIP DETAILS LINK)\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'facilities',\n",
              "   'patterns': ['What facilities college provide',\n",
              "    'College facility',\n",
              "    'What are college facilities',\n",
              "    'facilities',\n",
              "    'facilities provided'],\n",
              "   'responses': [\"Our university's Engineering department provides fully AC Lab with internet connection, smart classroom, Auditorium, library,canteen\"],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'college intake',\n",
              "   'patterns': ['max number of students',\n",
              "    'number of seats per branch',\n",
              "    'number of seats in each branch',\n",
              "    'maximum number of seats',\n",
              "    'maximum students intake',\n",
              "    'What is college intake',\n",
              "    'how many stundent are taken in each branch',\n",
              "    'seat allotment',\n",
              "    'seats'],\n",
              "   'responses': ['For IT, Computer and extc 60 per branch and seat may be differ for different department.'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'uniform',\n",
              "   'patterns': ['college dress code',\n",
              "    'college dresscode',\n",
              "    'what is the uniform',\n",
              "    'can we wear casuals',\n",
              "    'Does college have an uniform',\n",
              "    'Is there any uniform',\n",
              "    'uniform',\n",
              "    'what about uniform',\n",
              "    'do we have to wear uniform'],\n",
              "   'responses': ['ENTER YOUR OWN UNIVERSITY UNIFORM CIRCULER'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'committee',\n",
              "   'patterns': ['what are the different committe in college',\n",
              "    'different committee in college',\n",
              "    'Are there any committee in college',\n",
              "    'Give me committee details',\n",
              "    'committee',\n",
              "    'how many committee are there in college'],\n",
              "   'responses': ['For the various committe in college contact this number: ADD NUMBER'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'random',\n",
              "   'patterns': ['I love you', 'Will you marry me', 'Do you love me'],\n",
              "   'responses': ['I am not program for this, please ask appropriate query'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'swear',\n",
              "   'patterns': ['fuck',\n",
              "    'bitch',\n",
              "    'shut up',\n",
              "    'hell',\n",
              "    'stupid',\n",
              "    'idiot',\n",
              "    'dumb ass',\n",
              "    'asshole',\n",
              "    'fucker'],\n",
              "   'responses': ['please use appropriate language',\n",
              "    'Maintaining decency would be appreciated'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'vacation',\n",
              "   'patterns': ['holidays',\n",
              "    'when will semester starts',\n",
              "    'when will semester end',\n",
              "    'when is the holidays',\n",
              "    'list of holidays',\n",
              "    'Holiday in these year',\n",
              "    'holiday list',\n",
              "    'about vacations',\n",
              "    'about holidays',\n",
              "    'When is vacation',\n",
              "    'When is holidays',\n",
              "    'how long will be the vacation'],\n",
              "   'responses': ['Academic calender is given to you by your class-soordinators after you join your respective classes'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'sports',\n",
              "   'patterns': ['sports and games',\n",
              "    'give sports details',\n",
              "    'sports infrastructure',\n",
              "    'sports facilities',\n",
              "    'information about sports',\n",
              "    'Sports activities',\n",
              "    'please provide sports and games information'],\n",
              "   'responses': ['Our university encourages all-round development of students and hence provides sports facilities in the campus. For more details visit<a target=\"_blank\" href=/\"(LINK IF HAVE)\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'salutaion',\n",
              "   'patterns': ['okk',\n",
              "    'okie',\n",
              "    'nice work',\n",
              "    'well done',\n",
              "    'good job',\n",
              "    'thanks for the help',\n",
              "    'Thank You',\n",
              "    'its ok',\n",
              "    'Thanks',\n",
              "    'Good work',\n",
              "    'k',\n",
              "    'ok',\n",
              "    'okay'],\n",
              "   'responses': ['I am glad I helped you',\n",
              "    'welcome, anything else i can assist you with?'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'task',\n",
              "   'patterns': ['what can you do',\n",
              "    'what are the thing you can do',\n",
              "    'things you can do',\n",
              "    'what can u do for me',\n",
              "    'how u can help me',\n",
              "    'why i should use you'],\n",
              "   'responses': ['I can answer to low-intermediate questions regarding college',\n",
              "    'You can ask me questions regarding college, and i will try to answer them'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'ragging',\n",
              "   'patterns': ['ragging',\n",
              "    'is ragging practice active in college',\n",
              "    'does college have any antiragging facility',\n",
              "    'is there any ragging cases',\n",
              "    'is ragging done here',\n",
              "    'ragging against',\n",
              "    'antiragging facility',\n",
              "    'ragging juniors',\n",
              "    'ragging history',\n",
              "    'ragging incidents'],\n",
              "   'responses': ['We are Proud to tell you that our college provides ragging free environment, and we have strict rules against ragging'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'hod',\n",
              "   'patterns': ['hod', 'hod name', 'who is the hod'],\n",
              "   'responses': ['HODs differ for each branch, please be more specific like: (HOD it)'],\n",
              "   'context_set': ''}]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre-Processing:"
      ],
      "metadata": {
        "id": "oJWPdqyg1tKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in intents['intents']:\n",
        "    for p in i['patterns']:\n",
        "\n",
        "        #tokenize each word\n",
        "        w = nltk.word_tokenize(p)\n",
        "        words.extend(w)\n",
        "        documents.append((w, i['tag']))\n",
        "        if i['tag'] not in tags:\n",
        "            tags.append(i['tag'])"
      ],
      "metadata": {
        "id": "nNn5TbF4_rFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in puncc]\n",
        "words = sorted(list(set(words)))\n",
        "# sort classes\n",
        "tags = sorted(list(set(tags)))\n",
        "# documents = combination between patterns and intents\n",
        "print (len(documents), \"documents\")\n",
        "# classes = intents\n",
        "print (len(tags), \"classes\", tags)\n",
        "# words = all words\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(tags,open('classes.pkl','wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfrUP--TEx3a",
        "outputId": "07220900-2954-4f9f-ad28-216608791a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "405 documents\n",
            "38 classes ['admission', 'canteen', 'college intake', 'committee', 'computerhod', 'course', 'creator', 'document', 'event', 'extchod', 'facilities', 'fees', 'floors', 'goodbye', 'greeting', 'hod', 'hostel', 'hours', 'infrastructure', 'ithod', 'library', 'location', 'menu', 'name', 'number', 'placement', 'principal', 'ragging', 'random', 'salutaion', 'scholarship', 'sem', 'sports', 'swear', 'syllabus', 'task', 'uniform', 'vacation']\n",
            "263 unique lemmatized words [\"'s\", '(', ')', 'a', 'about', 'ac', 'active', 'activity', 'address', 'admision', 'admission', 'against', 'ai/ml', 'allotment', 'am', 'an', 'and', 'antiragging', 'any', 'anyone', 'are', 'as', 'asshole', 'at', 'attend', 'automobile', 'available', 'average', 'be', 'between', 'big', 'bitch', 'book', 'boy', 'branch', 'bring', 'building', 'by', 'bye', 'cafetaria', 'call', 'called', 'campus', 'can', 'canteen', 'capacity', 'case', 'casuals', 'ce', 'chatting', 'chemical', 'civil', 'code', 'college', 'come', 'committe', 'committee', 'comp', 'company', 'computer', 'conducted', 'contact', 'course', 'create', 'created', 'creator', 'cya', 'date', 'day', 'designed', 'detail', 'developer', 'different', 'distance', 'do', 'document', 'doe', 'done', 'dress', 'dresscode', 'dumb', 'during', 'each', 'eat', 'end', 'engineering', 'event', 'exam', 'extc', 'facility', 'far', 'fee', 'first', 'floor', 'food', 'for', 'fourth', 'from', 'fuck', 'fucker', 'function', 'game', 'get', 'girl', 'give', 'go', 'good', 'goodbye', 'got', 'gtg', 'guy', 'have', 'held', 'hell', 'hello', 'help', 'here', 'heyy', 'hi', 'history', 'hod', 'holiday', 'hostel', 'hour', 'how', 'i', 'idiot', 'in', 'incident', 'info', 'information', 'infrastructure', 'intake', 'is', 'it', 'job', 'junior', 'k', 'later', 'leaving', 'lecture', 'library', 'list', 'located', 'location', 'long', 'love', 'made', 'many', 'marry', 'max', 'maximum', 'me', 'mechanical', 'menu', 'more', 'much', 'my', 'name', 'need', 'needed', 'next', 'nice', 'no', 'non-ac', 'number', 'of', 'offer', 'offered', 'office', 'ok', 'okay', 'okie', 'okk', 'on', 'open', 'operation', 'organised', 'package', 'per', 'phone', 'placement', 'please', 'practice', 'principal', 'process', 'provide', 'provided', 'ragging', 'reach', 'recruitment', 'required', 'room', 'saturday', 'schedule', 'scholarship', 'seat', 'second', 'see', 'sem', 'semester', 'servive', 'should', 'shut', 'size', 'something', 'sport', 'start', 'student', 'stundent', 'stupid', 'syllabus', 'take', 'taken', 'taking', 'talk', 'tall', 'technology', 'telephone', 'tell', 'thank', 'thanks', 'the', 'there', 'these', 'thing', 'third', 'this', 'time', 'timetable', 'timing', 'to', 'ttyl', 'u', 'uni', 'uniform', 'univrsity', 'up', 'use', 'vacation', 'variety', 'visit', 'we', 'wear', 'well', 'what', 'whats', 'whatsup', 'whatv', 'when', 'where', 'wheres', 'which', 'who', 'whom', 'why', 'will', 'work', 'working', 'ya', 'year', 'you', 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = []\n",
        "output = [0] * len(tags)\n",
        "for d in documents:\n",
        "    # initialize  bag of words\n",
        "    bag = []\n",
        "    pattern_words = d[0]\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    \n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "    output_row = list(output)\n",
        "    output_row[tags.index(d[1])] = 1\n",
        "    \n",
        "    train_df.append([bag, output_row])\n"
      ],
      "metadata": {
        "id": "LsSExaSyFmJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(train_df)\n",
        "train_df = np.array(train_df)\n",
        "train_x = list(train_df[:,0])\n",
        "train_y = list(train_df[:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr1Cf1fVHuvR",
        "outputId": "1f1f818f-953a-4d04-9c7a-973fceba15a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5d3a8ab30cb5>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train_df = np.array(train_df)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling:"
      ],
      "metadata": {
        "id": "7LFNjnv71-Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "#fitting and saving the model \n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRIetskIpSiH",
        "outputId": "1d9fe018-dbdc-4d07-f92f-1b55cfa0d513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "81/81 [==============================] - 2s 5ms/step - loss: 3.6198 - accuracy: 0.0420\n",
            "Epoch 2/200\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 3.4784 - accuracy: 0.1111\n",
            "Epoch 3/200\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 3.2498 - accuracy: 0.1679\n",
            "Epoch 4/200\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 3.0354 - accuracy: 0.2099\n",
            "Epoch 5/200\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 2.7689 - accuracy: 0.2938\n",
            "Epoch 6/200\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 2.5312 - accuracy: 0.3556\n",
            "Epoch 7/200\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 2.2932 - accuracy: 0.4222\n",
            "Epoch 8/200\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 2.0674 - accuracy: 0.4617\n",
            "Epoch 9/200\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 1.8666 - accuracy: 0.5259\n",
            "Epoch 10/200\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 1.7030 - accuracy: 0.5605\n",
            "Epoch 11/200\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 1.5467 - accuracy: 0.6148\n",
            "Epoch 12/200\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 1.4024 - accuracy: 0.6370\n",
            "Epoch 13/200\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 1.3120 - accuracy: 0.6617\n",
            "Epoch 14/200\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 1.1782 - accuracy: 0.7012\n",
            "Epoch 15/200\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 1.1272 - accuracy: 0.6963\n",
            "Epoch 16/200\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.9881 - accuracy: 0.7580\n",
            "Epoch 17/200\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 0.9639 - accuracy: 0.7704\n",
            "Epoch 18/200\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.8700 - accuracy: 0.7926\n",
            "Epoch 19/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.8111 - accuracy: 0.7728\n",
            "Epoch 20/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7682 - accuracy: 0.8074\n",
            "Epoch 21/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.8519\n",
            "Epoch 22/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.8222\n",
            "Epoch 23/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.8321\n",
            "Epoch 24/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.8741\n",
            "Epoch 25/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.8617\n",
            "Epoch 26/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.8494\n",
            "Epoch 27/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.8765\n",
            "Epoch 28/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8864\n",
            "Epoch 29/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8889\n",
            "Epoch 30/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8691\n",
            "Epoch 31/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.9037\n",
            "Epoch 32/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8914\n",
            "Epoch 33/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8790\n",
            "Epoch 34/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8938\n",
            "Epoch 35/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8765\n",
            "Epoch 36/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.9259\n",
            "Epoch 37/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.9210\n",
            "Epoch 38/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.9185\n",
            "Epoch 39/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8938\n",
            "Epoch 40/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.9086\n",
            "Epoch 41/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.9309\n",
            "Epoch 42/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.9111\n",
            "Epoch 43/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.9457\n",
            "Epoch 44/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.9185\n",
            "Epoch 45/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.9210\n",
            "Epoch 46/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.9235\n",
            "Epoch 47/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9309\n",
            "Epoch 48/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.9383\n",
            "Epoch 49/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 0.9284\n",
            "Epoch 50/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9160\n",
            "Epoch 51/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9259\n",
            "Epoch 52/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9432\n",
            "Epoch 53/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9309\n",
            "Epoch 54/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2214 - accuracy: 0.9333\n",
            "Epoch 55/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2428 - accuracy: 0.9235\n",
            "Epoch 56/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9383\n",
            "Epoch 57/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9556\n",
            "Epoch 58/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2014 - accuracy: 0.9457\n",
            "Epoch 59/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1841 - accuracy: 0.9407\n",
            "Epoch 60/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.9210\n",
            "Epoch 61/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9506\n",
            "Epoch 62/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9481\n",
            "Epoch 63/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9457\n",
            "Epoch 64/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9630\n",
            "Epoch 65/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.9432\n",
            "Epoch 66/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9556\n",
            "Epoch 67/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9654\n",
            "Epoch 68/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9481\n",
            "Epoch 69/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9432\n",
            "Epoch 70/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9605\n",
            "Epoch 71/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9407\n",
            "Epoch 72/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9654\n",
            "Epoch 73/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9481\n",
            "Epoch 74/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9383\n",
            "Epoch 75/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9531\n",
            "Epoch 76/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9407\n",
            "Epoch 77/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9605\n",
            "Epoch 78/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9580\n",
            "Epoch 79/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9704\n",
            "Epoch 80/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9630\n",
            "Epoch 81/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9630\n",
            "Epoch 82/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9531\n",
            "Epoch 83/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9679\n",
            "Epoch 84/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9457\n",
            "Epoch 85/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9556\n",
            "Epoch 86/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9531\n",
            "Epoch 87/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9556\n",
            "Epoch 88/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9679\n",
            "Epoch 89/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9531\n",
            "Epoch 90/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9556\n",
            "Epoch 91/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9556\n",
            "Epoch 92/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9457\n",
            "Epoch 93/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9383\n",
            "Epoch 94/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9704\n",
            "Epoch 95/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9580\n",
            "Epoch 96/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9506\n",
            "Epoch 97/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9753\n",
            "Epoch 98/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9778\n",
            "Epoch 99/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9704\n",
            "Epoch 100/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9556\n",
            "Epoch 101/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9654\n",
            "Epoch 102/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9704\n",
            "Epoch 103/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9728\n",
            "Epoch 104/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9605\n",
            "Epoch 105/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9778\n",
            "Epoch 106/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9704\n",
            "Epoch 107/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9704\n",
            "Epoch 108/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9728\n",
            "Epoch 109/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9704\n",
            "Epoch 110/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9556\n",
            "Epoch 111/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.9630\n",
            "Epoch 112/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9605\n",
            "Epoch 113/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9556\n",
            "Epoch 114/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9852\n",
            "Epoch 115/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9630\n",
            "Epoch 116/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9654\n",
            "Epoch 117/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9778\n",
            "Epoch 118/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9802\n",
            "Epoch 119/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9778\n",
            "Epoch 120/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9728\n",
            "Epoch 121/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9630\n",
            "Epoch 122/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9753\n",
            "Epoch 123/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9556\n",
            "Epoch 124/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9605\n",
            "Epoch 125/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9728\n",
            "Epoch 126/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9753\n",
            "Epoch 127/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9556\n",
            "Epoch 128/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9753\n",
            "Epoch 129/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9704\n",
            "Epoch 130/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9679\n",
            "Epoch 131/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9753\n",
            "Epoch 132/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9630\n",
            "Epoch 133/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9728\n",
            "Epoch 134/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9605\n",
            "Epoch 135/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9753\n",
            "Epoch 136/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9704\n",
            "Epoch 137/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9753\n",
            "Epoch 138/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9802\n",
            "Epoch 139/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9778\n",
            "Epoch 140/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9704\n",
            "Epoch 141/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9654\n",
            "Epoch 142/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9753\n",
            "Epoch 143/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9654\n",
            "Epoch 144/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9778\n",
            "Epoch 145/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9580\n",
            "Epoch 146/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9753\n",
            "Epoch 147/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9630\n",
            "Epoch 148/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9827\n",
            "Epoch 149/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9728\n",
            "Epoch 150/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9778\n",
            "Epoch 151/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9728\n",
            "Epoch 152/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9679\n",
            "Epoch 153/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9728\n",
            "Epoch 154/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9704\n",
            "Epoch 155/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9877\n",
            "Epoch 156/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9679\n",
            "Epoch 157/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9827\n",
            "Epoch 158/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9654\n",
            "Epoch 159/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9852\n",
            "Epoch 160/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9778\n",
            "Epoch 161/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9827\n",
            "Epoch 162/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.9605\n",
            "Epoch 163/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9654\n",
            "Epoch 164/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9704\n",
            "Epoch 165/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9679\n",
            "Epoch 166/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9728\n",
            "Epoch 167/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9802\n",
            "Epoch 168/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9753\n",
            "Epoch 169/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9827\n",
            "Epoch 170/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9827\n",
            "Epoch 171/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9778\n",
            "Epoch 172/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9827\n",
            "Epoch 173/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9728\n",
            "Epoch 174/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9704\n",
            "Epoch 175/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9852\n",
            "Epoch 176/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9679\n",
            "Epoch 177/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9679\n",
            "Epoch 178/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9630\n",
            "Epoch 179/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9778\n",
            "Epoch 180/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9753\n",
            "Epoch 181/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9926\n",
            "Epoch 182/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9802\n",
            "Epoch 183/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9556\n",
            "Epoch 184/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9704\n",
            "Epoch 185/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9827\n",
            "Epoch 186/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9778\n",
            "Epoch 187/200\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9901\n",
            "Epoch 188/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9877\n",
            "Epoch 189/200\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9802\n",
            "Epoch 190/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9802\n",
            "Epoch 191/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9827\n",
            "Epoch 192/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9778\n",
            "Epoch 193/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9679\n",
            "Epoch 194/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9679\n",
            "Epoch 195/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9728\n",
            "Epoch 196/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9926\n",
            "Epoch 197/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9852\n",
            "Epoch 198/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9827\n",
            "Epoch 199/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9852\n",
            "Epoch 200/200\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('chatbot_model.h5', hist)"
      ],
      "metadata": {
        "id": "x8a5_cJLdO9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('chatbot_model.h5')\n",
        "intents = json.loads(open('intents.json').read())\n",
        "words = pickle.load(open('words.pkl','rb'))\n",
        "classes = pickle.load(open('classes.pkl','rb'))"
      ],
      "metadata": {
        "id": "mmrmJK4GREKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions:"
      ],
      "metadata": {
        "id": "rlw3zEth2E7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_input(input):\n",
        "    sentence_words = nltk.word_tokenize(input)\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "\n",
        "def bow(input, words, show_details=True):\n",
        "\n",
        "    sentence_words = clean_input(input)\n",
        "    bag = [0]*len(words) \n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s: \n",
        "                # assign 1 if current word is in the vocabulary position\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "    return(np.array(bag))\n",
        "\n",
        "def predict_tag(input, model):\n",
        "    p = bow(input, words,show_details=False)\n",
        "    res = model.predict(np.array([p]),verbose=0)[0];\n",
        "    results = [[i,r] for i,r in enumerate(res) ]\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    return return_list\n",
        "\n",
        "def getResponse(ints, intents_json):\n",
        "    tag = ints[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if(i['tag']== tag):\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "def chatbot_answer(text):\n",
        "    ints = predict_tag(text, model)\n",
        "    res = getResponse(ints, intents)\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "osUe2K7nSkb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"hi I am aya\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfl5rmU-2iOj",
        "outputId": "2fd07da7-6b45-4d25-9941-057f52a92046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good to see you again!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"how are you?\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNCLeRAFTQW4",
        "outputId": "5094ee93-8c4c-4122-99bc-6e63eed33bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there, how can I help?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"what is your name\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRz8TNq8lyAx",
        "outputId": "f28cc2b0-b184-4b68-8c4e-f58100f85b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a Chatbot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"?????\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-h04AS6qDmx",
        "outputId": "ef13bf58-1986-4990-8b13-b29a3ae22f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there, how can I help?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"Does college have canteen\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObOByKBaqF-Z",
        "outputId": "377677ef-00ff-4dc2-fcf1-8f78578b4301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our university has canteen with variety of food available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"holiday list\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_MaNC-vqJAB",
        "outputId": "77739728-16f9-4210-b90b-a2ef53798406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Academic calender is given to you by your class-soordinators after you join your respective classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"sports facilities\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcz_7con6a6h",
        "outputId": "4f4ce4fd-bae7-498d-e147-243b760ac861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our university encourages all-round development of students and hence provides sports facilities in the campus. For more details visit<a target=\"_blank\" href=/\"(LINK IF HAVE)\">here</a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"bye\"\n",
        "res = chatbot_answer(msg)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqJ2WEdP6e6w",
        "outputId": "54920723-d350-458f-b1fb-04e00040e944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}